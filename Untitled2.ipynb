{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a20f61dc76a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;31m#_, updated = tf.while_loop(lambda i, _: tf.less(i, 5), body, [0, my_variable])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m#sess.run(ini_matmul)  # force initialisation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np \n",
    "\n",
    "tfd = tfp.distributions\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "#tf.enable_eager_execution()\n",
    "i = tf.constant(0)\n",
    "dimension = 11\n",
    "\n",
    "repeat = 600\n",
    "use_gpu = False\n",
    "num_articles=321\n",
    "num_arm_features=305\n",
    "\n",
    "alpha=0.1\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "def recommend(query_id, page_id, ratings):\n",
    "    MIN_PROBABILITY = tf.constant(0.0)\n",
    "    POSITIVE_RATING_VAL = tf.constant(1)\n",
    "    clicked = tf.constant(1.0)\n",
    "    tfzero = tf.constant(0)\n",
    "    \n",
    "#     def if_true(fixed_rewads=True):\n",
    "#         if fixed_rewards:\n",
    "#             return clicked\n",
    "#         else:\n",
    "#             return tfd.Binomial(total_count=1, logits=0.9)        \n",
    "        \n",
    "#     @tf.function\n",
    "#     def pred(a,b):\n",
    "#         if tf.math.equal(a,b):\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     def if_false():   \n",
    "        \n",
    "#         current_page_feature=X_page[page_id]\n",
    "#         current_query_features=X_query[query_id]\n",
    "#         query_ratings = X_ratings[:,page_id]\n",
    "#         query_pos_rat_idxs = tf.where(query_ratings)\n",
    "#         query_pos_rat_idxs_size = tf.reshape(tf.size(query_pos_rat_idxs),[])\n",
    "#         sess = tf.Session()\n",
    "#         result = tf.cond(pred(query_pos_rat_idxs_size,tfzero), return_minprob, return_normalprob)\n",
    "#         return result\n",
    "   \n",
    "    \n",
    "#     def return_minprob():\n",
    "#         return tf.constant(0.0)\n",
    "    \n",
    "#     def return_normalprob():\n",
    "#         tp1 = tf.gather_nd(X_query,query_pos_rat_idxs)\n",
    "#         tp2 = tf.reshape(tf.nn.l2_normalize(current_query_features, 0),[300,1])\n",
    "#         print(tp2)\n",
    "#         tp3 = tf.reshape(tf.nn.l2_normalize(tp1, 0),[300,1])\n",
    "#         match_likabilities = tf.keras.metrics.CosineSimilarity(tp2, tp3)\n",
    "#         print(match_likabilities)\n",
    "#         result_match_likability = tf.math.reduce_mean(match_likabilities)\n",
    "#         tfzeros = tf.to_float(tf.constant(0))\n",
    "#         binomial_reward_probability = tf.cond(result_match_likability < tfzeros, lambda: MIN_PROBABILITY, lambda: result_match_likability)    \n",
    "#         #return result, query_ratings, query_pos_rat_idxs, tp1, tp2, tp3, result_match_likability, binomial_reward_probability\n",
    "#         return binomial_reward_probability\n",
    "    \n",
    "    \n",
    "# #     my_ratings =tf.gather_nd(X_ratings, tf.stack((page_id, query_id), -1)) \n",
    "# #     result = tf.cond(tf.math.equal(my_ratings,POSITIVE_RATING_VAL), if_true, if_false )\n",
    "    \n",
    "# #    return result\n",
    "# #    current_page_feature=tf.compat.v1.gather_nd(X_page, page_id, -1)\n",
    "#     print(X_page)\n",
    "#     print(page_id)\n",
    "#     #current_page_feature=X_page[page_id]\n",
    "#     current_page_feature=tf.gather_nd(X_page,page_id)\n",
    "#     current_query_features=X_query[query_id]\n",
    "#     #query_ratings = X_ratings[:,page_id]\n",
    "#     query_ratings = tf.gather_nd(X_ratings,page_id)\n",
    "#     query_pos_rat_idxs = tf.where(query_ratings)\n",
    "#     query_pos_rat_idxs_size = tf.size(query_pos_rat_idxs)\n",
    "    \n",
    "    #result = tf.cond(pred(query_pos_rat_idxs_size,tfzero), return_minprob, return_normalprob)\n",
    "    \n",
    "    #result = tfd.Binomial(total_count=1, logits=0.9)  \n",
    "    result = np.random.binomial(n=1, p=0.2)   \n",
    "#     print(query_pos_rat_idxs)\n",
    "#     tp1 = tf.gather_nd(X_query,query_pos_rat_idxs)\n",
    "#     tp2 = tf.reshape(tf.nn.l2_normalize(current_query_features, 0),[300,1])\n",
    "#     print(tp2)\n",
    "#     tp3 = tf.reshape(tf.nn.l2_normalize(tp1, 0),[300,1])\n",
    "#     match_likabilities = tf.losses.cosine_distance(tp2, tp3, dim=0)\n",
    "#     print(match_likabilities)\n",
    "#     result_match_likability = tf.math.reduce_mean(match_likabilities)\n",
    "#     tfzeros = tf.to_float(tf.constant(0))\n",
    "#     binomial_reward_probability = tf.cond(result_match_likability < tfzeros, lambda: MIN_PROBABILITY, lambda: result_match_likability)    \n",
    "    return result\n",
    "\n",
    "def get_arm_features(i,j, X_query, X_page):\n",
    "    current_query_features=X_query[i]\n",
    "    current_page_feature=X_page[j]\n",
    "    print(current_query_features)\n",
    "    print(current_page_feature)\n",
    "    \n",
    "    return tf.concat([current_query_features,current_page_feature],0)\n",
    "    #return tf.ones([305,1])\n",
    "\n",
    "def body2(q_id, query_features, A, b, page_features, r_t):\n",
    "    \n",
    "    #print(tf.reshape(query_features[q_id,:],[300,1]))\n",
    "    # tile the given query features\n",
    "    q = tf.tile(\n",
    "        tf.transpose(tf.reshape(query_features[q_id,:],[300,1])), [321,1], name='q'\n",
    "    )\n",
    "    q = tf.cast(q, dtype=tf.float32, name='q') \n",
    "\n",
    "    # combine query features with all page features\n",
    "    arm_f = tf.transpose(tf.transpose(tf.concat([q,X_page],1)))\n",
    "    \n",
    "    x_t = tf.expand_dims(arm_f, -1) # add a new dimension\n",
    "\n",
    "    # calculate theta, theta needs to be updated by loop\n",
    "    theta = tf.linalg.solve(E + A, b)\n",
    "    \n",
    "    g_t_a = tf.linalg.solve(E+A, x_t)\n",
    "    \n",
    "    p_t_a = tf.add(tf.matmul(tf.transpose(theta,[0,2,1]), x_t),alpha*tf.sqrt(tf.matmul(tf.transpose(x_t,[0,2,1]),g_t_a)))\n",
    "    \n",
    "    \n",
    "    # move to next query\n",
    "    add = tf.add(q_id, 1)\n",
    "    \n",
    "\n",
    "    # pick the maxone \n",
    "    a_t= tf.argmax(p_t_a, axis=0)\n",
    "    r_t_new = recommend(query_id=q_id, page_id=a_t, ratings=ratings)\n",
    "    print(r_t_new)\n",
    "    r_t = tf.add(r_t, r_t_new)\n",
    "\n",
    "    print(r_t)\n",
    "#     print(query_features[q_id,:])\n",
    "    \n",
    "    current_page_feature = tf.reshape(tf.gather_nd(page_features, a_t),[5,1])\n",
    "    print(current_page_feature)\n",
    "    x_t_at = tf.concat([tf.reshape(query_features[q_id,:],[300,1]),current_page_feature],0)\n",
    "\n",
    "    #A_a_t = A[a_t,:]\n",
    "    A_a_t = tf.gather_nd(A, a_t)\n",
    "    A_a_t_new = tf.add(tf.to_float(A_a_t), tf.to_float(tf.matmul(tf.reshape(x_t_at,[305,-1]), tf.transpose(tf.reshape(x_t_at,[305,-1])))))\n",
    "    \n",
    "    #print(\"b_a_t\")\n",
    "    #b_a_t = b[a_t]\n",
    "    b_a_t = tf.gather_nd(b, a_t)\n",
    "    #print(b_a_t)\n",
    "    \n",
    "    b_a_t_new = tf.add(b_a_t,r_t*tf.to_float(x_t_at))\n",
    "    #print(\"b_a_t_new\")\n",
    "    #print(b_a_t_new)\n",
    "\n",
    "#     print(A)\n",
    "#     print(A_a_t_new)\n",
    "#     print(tf.expand_dims(A_a_t_new,0))\n",
    "    \n",
    "#     print(b)\n",
    "#     print(tf.expand_dims(b_a_t_new,0))\n",
    "#     delta_A_a_t_value = new_value - v[index:index+1]\n",
    "#     delta = tf.SparseTensor([[index]], delta_value, (5,))\n",
    "\n",
    "    rand_t = tf.math.scalar_mul(tf.to_float(q_id), tf.ones([305,1]), name='rand_t')\n",
    "    ind_part_1 = tf.range(a_t[0][0])\n",
    "    #print(ind_part_1)\n",
    "    ind_part_2 = tf.range(tf.add(a_t[0][0],1),305)\n",
    "    \n",
    "    A_part_1 = tf.gather_nd(A,ind_part_1)\n",
    "    A_part_2 = tf.gather_nd(A,ind_part_2)\n",
    "#     A = tf.concat([A[:a_t], tf.expand_dims(A_a_t_new,0), A[a_t+1:]], axis = 0 )\n",
    "#     b = tf.concat([b[:a_t], tf.expand_dims(rand_t,0), b[a_t+1:]], axis = 0 )\n",
    "    #print(b)\n",
    "#     tf.scatter_nd_update(A,[a_t],A_a_t_new)\n",
    "#     tf.scatter_nd_update(b,[a_t],b_a_t_new)\n",
    "    return [add, query_features, A, b, page_features, r_t]    \n",
    "    \n",
    "def body(i, j):\n",
    "    print(i)\n",
    "    res = tf.add(j, 2)\n",
    "    add = tf.add(i, 1)\n",
    "    return (add, res)\n",
    "    \n",
    "a = tf.constant(1.1, shape=[2**dimension, 2**dimension])\n",
    "c = tf.constant(2.2, shape=[2**dimension, 2**dimension])    \n",
    "# do the loop:\n",
    "\n",
    "\n",
    "\n",
    "# ini_matmul = tf.matmul(a, b)\n",
    "\n",
    "\n",
    "\n",
    "# while_condition = lambda i, _: tf.less(i, repeat)\n",
    "# loop, res = tf.while_loop(while_condition, body, [i, 0])\n",
    "#_, updated = tf.while_loop(lambda i, _: tf.less(i, 5), body, [0, my_variable])\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        #sess.run(ini_matmul)  # force initialisation.\n",
    "    init = tf.global_variables_initializer()        \n",
    "    query_features=pickle.load(open('data/X_train_bow_features.pkl','rb'))\n",
    "    page_features=pickle.load(open('data/X_all_page_pca_features.pkl','rb'))\n",
    "    ratings = pickle.load(open('data/Y_train_labels.pkl','rb'))\n",
    "    ident = tf.eye(num_arm_features)\n",
    "\n",
    "    X_page = tf.constant(page_features, dtype=tf.float32, name=\"X_page\")\n",
    "    X_query = tf.constant(query_features, dtype=tf.float32, name=\"X_query\")\n",
    "    X_ratings = tf.constant(ratings, dtype=tf.int32, name=\"X_ratings\")\n",
    "\n",
    "    A = tf.Variable(tf.ones([num_articles, 1, 1], name='A') * ident)\n",
    "    print(\"A\", A)\n",
    "    E = tf.Variable(tf.ones([num_articles, 1, 1], name='E') * ident)\n",
    "    bv = tf.Variable(tf.zeros([num_arm_features, 1], name='bv'))\n",
    "    b = tf.Variable(tf.ones([num_articles, 1, 1], name='b') * bv)\n",
    "    print(\"b\",b)\n",
    "    t0 = time.time()\n",
    "    r_t = tf.constant(0.0)\n",
    "    while_condition =   lambda i, _1, _2, b, _3, r_t: tf.less(i, repeat)\n",
    "    loop, _1, A, b, _3, r_t= tf.while_loop(while_condition, body2, [i, query_features, A, b, page_features, r_t])    \n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    #print(sess.run(loop))\n",
    "   \n",
    "    print(\"rt ==\"+str(sess.run(r_t)))\n",
    "    print(sess.run(loop))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Dimension {dim:d}, Repeat: {r:d}, Time cost: {t:.8f} seconds.'.format(\n",
    "        dim = dimension, r = repeat,\n",
    "        t = t1 - t0\n",
    "    ))\n",
    "sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X_page_4:0' shape=(321, 5) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rand_t_3:0' shape=(305, 1) dtype=float32>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_t = tf.ones([305,1], name='rand_t')\n",
    "rand_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.concat([b[:3], tf.expand_dims(rand_t,0), b[4:]], axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Dimension 11, Repeat: 600, Time cost: 1.05756116 seconds.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    #sess.run(ini_matmul)  # force initialisation.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    t0 = time.time()\n",
    "    #print(sess.run(loop))\n",
    "    print(sess.run(b[3]))\n",
    "    t1 = time.time()\n",
    "    print('Dimension {dim:d}, Repeat: {r:d}, Time cost: {t:.8f} seconds.'.format(\n",
    "        dim = dimension, r = repeat,\n",
    "        t = t1 - t0\n",
    "    ))\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'while_39/Exit_2:0' shape=(321, 305, 305) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVar = tf.Variable(tf.zeros([5,1]))\n",
    "ind = tf.constant([0,3])\n",
    "#data = tf.constant([5,7], dtype=tf.float32)\n",
    "data = tf.expand_dims(tf.constant([5,7], dtype=tf.float32),1)\n",
    "up = tf.scatter_update(testVar,  ind,  data  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_2:0' shape=(2, 1) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_35:0' shape=(5, 1) dtype=float32_ref>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_44:0' shape=(321, 305, 305) dtype=float32_ref>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "num = tf.zeros( shape = ( 5, 3 ), dtype = tf.float32 )\n",
    "# Looping variable\n",
    "i = tf.zeros( shape=(), dtype=tf.int32)\n",
    "# Conditional\n",
    "c = lambda i, num: tf.less(i, 2)\n",
    "def body(i, num):\n",
    "    # Update values\n",
    "    updates = tf.ones([1, 3], dtype=tf.float32)\n",
    "    num_shape = num.get_shape()\n",
    "    num = tf.concat( [ num[ : i ], updates, num[ i + 1 : ] ], axis = 0 )\n",
    "    num.set_shape( num_shape )\n",
    "    return tf.add(i, tf.ones( shape=(), dtype = tf.int32 ) ), num\n",
    "i, num = tf.while_loop( c, body, [ i, num ] )\n",
    "# Session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_out = sess.run( [ num ] )\n",
    "    print(num_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  tf.range(tf.constant(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2=tf.range(tf.add(tf.constant(3),1),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'range_2:0' shape=(6,) dtype=int32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
