{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8283678]\n",
      " [0.9316438]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(444)\n",
    "\n",
    "N = 10000\n",
    "sigma = 0.1\n",
    "noise = sigma * np.random.randn(N)\n",
    "x = np.linspace(0, 2, N)\n",
    "d = 3 + 2 * x + noise\n",
    "d.shape = (N, 1)\n",
    "\n",
    "# We need to prepend a column vector of 1s to `x`.\n",
    "X = np.column_stack((np.ones(N, dtype=x.dtype), x))\n",
    "\n",
    "mu = 0.01\n",
    "\n",
    "def tf_descent(X_tf, d_tf, mu, N_epochs):\n",
    "    N = X_tf.get_shape().as_list()[0]\n",
    "    f = 2 / N\n",
    "\n",
    "    w = tf.Variable(tf.zeros((2, 1)), name=\"w_tf\")\n",
    "    y = tf.matmul(X_tf, w, name=\"y_tf\")\n",
    "    e = y - d_tf\n",
    "    grad = f * tf.matmul(tf.transpose(X_tf), e)\n",
    "\n",
    "    training_op = tf.assign(w, w - mu * grad)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(N_epochs):\n",
    "            sess.run(training_op)\n",
    "        opt = w.eval()\n",
    "    return opt\n",
    "\n",
    "X_tf = tf.constant(X, dtype=tf.float32, name=\"X_tf\")\n",
    "d_tf = tf.constant(d, dtype=tf.float32, name=\"d_tf\")\n",
    "\n",
    "tf_w = tf_descent(X_tf, d_tf, mu, 10)\n",
    "print(tf_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 2),\n",
       " (2, 6),\n",
       " (3, 7),\n",
       " (4, 6),\n",
       " (5, 14),\n",
       " (6, 16),\n",
       " (7, 13),\n",
       " (8, 17),\n",
       " (9, 19),\n",
       " (10, 20),\n",
       " (11, 8),\n",
       " (12, 24),\n",
       " (13, 25),\n",
       " (14, 25),\n",
       " (15, 25),\n",
       " (16, 25),\n",
       " (17, 25),\n",
       " (18, 25),\n",
       " (19, 31),\n",
       " (20, 32),\n",
       " (21, 25),\n",
       " (22, 37),\n",
       " (23, 38),\n",
       " (24, 26),\n",
       " (25, 42),\n",
       " (26, 45),\n",
       " (27, 42),\n",
       " (28, 49),\n",
       " (29, 51),\n",
       " (30, 53),\n",
       " (31, 42),\n",
       " (32, 42),\n",
       " (33, 57),\n",
       " (34, 42),\n",
       " (35, 45),\n",
       " (36, 42),\n",
       " (37, 65),\n",
       " (38, 62),\n",
       " (39, 21),\n",
       " (40, 70),\n",
       " (41, 9),\n",
       " (42, 21),\n",
       " (43, 16),\n",
       " (44, 71),\n",
       " (45, 19),\n",
       " (46, 2),\n",
       " (47, 77),\n",
       " (48, 79),\n",
       " (49, 80),\n",
       " (50, 84),\n",
       " (51, 46),\n",
       " (52, 76),\n",
       " (53, 89),\n",
       " (54, 2),\n",
       " (55, 77),\n",
       " (56, 90),\n",
       " (57, 91),\n",
       " (58, 92),\n",
       " (59, 93),\n",
       " (60, 47),\n",
       " (61, 97),\n",
       " (62, 60),\n",
       " (63, 55),\n",
       " (64, 104),\n",
       " (65, 105),\n",
       " (66, 105),\n",
       " (67, 107),\n",
       " (68, 109),\n",
       " (69, 110),\n",
       " (70, 111),\n",
       " (71, 113),\n",
       " (72, 114),\n",
       " (73, 115),\n",
       " (74, 117),\n",
       " (75, 117),\n",
       " (76, 119),\n",
       " (77, 120),\n",
       " (78, 110),\n",
       " (79, 107),\n",
       " (80, 116),\n",
       " (81, 116),\n",
       " (82, 116),\n",
       " (83, 117),\n",
       " (84, 124),\n",
       " (85, 125),\n",
       " (86, 125),\n",
       " (87, 124),\n",
       " (88, 124),\n",
       " (89, 130),\n",
       " (90, 125),\n",
       " (91, 124),\n",
       " (92, 125),\n",
       " (93, 124),\n",
       " (94, 127),\n",
       " (95, 124),\n",
       " (96, 124),\n",
       " (97, 124),\n",
       " (98, 124),\n",
       " (99, 138),\n",
       " (100, 139),\n",
       " (101, 142),\n",
       " (102, 141),\n",
       " (103, 134),\n",
       " (104, 144),\n",
       " (105, 135),\n",
       " (106, 135),\n",
       " (107, 135),\n",
       " (108, 140),\n",
       " (109, 140),\n",
       " (110, 74),\n",
       " (111, 146),\n",
       " (112, 146),\n",
       " (113, 148),\n",
       " (114, 150),\n",
       " (115, 151),\n",
       " (116, 149),\n",
       " (117, 150),\n",
       " (118, 156),\n",
       " (119, 159),\n",
       " (120, 160),\n",
       " (121, 6),\n",
       " (122, 6),\n",
       " (123, 6),\n",
       " (124, 6),\n",
       " (125, 160),\n",
       " (126, 6),\n",
       " (127, 160),\n",
       " (128, 6),\n",
       " (129, 170),\n",
       " (130, 155),\n",
       " (131, 174),\n",
       " (132, 175),\n",
       " (133, 175),\n",
       " (134, 175),\n",
       " (135, 175),\n",
       " (136, 179),\n",
       " (137, 130),\n",
       " (138, 181),\n",
       " (139, 182),\n",
       " (140, 181),\n",
       " (141, 183),\n",
       " (142, 184),\n",
       " (143, 185),\n",
       " (144, 188),\n",
       " (145, 110),\n",
       " (146, 103),\n",
       " (147, 116),\n",
       " (148, 192),\n",
       " (149, 193),\n",
       " (150, 120),\n",
       " (151, 196),\n",
       " (152, 103),\n",
       " (153, 49),\n",
       " (154, 103),\n",
       " (155, 194),\n",
       " (156, 200),\n",
       " (157, 191),\n",
       " (158, 24),\n",
       " (159, 24),\n",
       " (160, 210),\n",
       " (161, 204),\n",
       " (162, 211),\n",
       " (163, 204),\n",
       " (164, 24),\n",
       " (165, 190),\n",
       " (166, 214),\n",
       " (167, 195),\n",
       " (168, 218),\n",
       " (169, 36),\n",
       " (170, 221),\n",
       " (171, 220),\n",
       " (172, 222),\n",
       " (173, 223),\n",
       " (174, 224),\n",
       " (175, 28),\n",
       " (176, 28),\n",
       " (177, 36),\n",
       " (178, 36),\n",
       " (179, 36),\n",
       " (180, 227),\n",
       " (181, 227),\n",
       " (182, 228),\n",
       " (183, 230),\n",
       " (184, 232),\n",
       " (185, 231),\n",
       " (186, 231),\n",
       " (187, 232),\n",
       " (188, 231),\n",
       " (189, 232),\n",
       " (190, 231),\n",
       " (191, 233),\n",
       " (192, 241),\n",
       " (193, 242),\n",
       " (194, 244),\n",
       " (195, 244),\n",
       " (196, 243),\n",
       " (197, 241),\n",
       " (198, 248),\n",
       " (199, 116),\n",
       " (200, 244),\n",
       " (201, 241),\n",
       " (202, 117),\n",
       " (203, 16),\n",
       " (204, 252),\n",
       " (205, 249),\n",
       " (206, 162),\n",
       " (207, 250),\n",
       " (208, 254),\n",
       " (209, 250),\n",
       " (210, 194),\n",
       " (211, 254),\n",
       " (212, 249),\n",
       " (213, 162),\n",
       " (214, 162),\n",
       " (215, 250),\n",
       " (216, 256),\n",
       " (217, 130),\n",
       " (218, 259),\n",
       " (219, 260),\n",
       " (220, 113),\n",
       " (221, 265),\n",
       " (222, 163),\n",
       " (223, 268),\n",
       " (224, 270),\n",
       " (225, 265),\n",
       " (226, 270),\n",
       " (227, 270),\n",
       " (228, 142),\n",
       " (229, 271),\n",
       " (230, 265),\n",
       " (231, 275),\n",
       " (232, 276),\n",
       " (233, 276),\n",
       " (234, 276),\n",
       " (235, 277),\n",
       " (236, 276),\n",
       " (237, 277),\n",
       " (238, 23),\n",
       " (239, 281),\n",
       " (240, 23),\n",
       " (241, 23),\n",
       " (242, 282),\n",
       " (243, 280),\n",
       " (244, 47),\n",
       " (245, 286),\n",
       " (246, 23),\n",
       " (247, 52),\n",
       " (248, 23),\n",
       " (249, 289),\n",
       " (250, 290),\n",
       " (251, 256),\n",
       " (252, 293),\n",
       " (253, 294),\n",
       " (254, 295),\n",
       " (255, 296),\n",
       " (256, 296),\n",
       " (257, 298),\n",
       " (258, 75),\n",
       " (259, 75),\n",
       " (260, 75),\n",
       " (261, 36),\n",
       " (262, 295),\n",
       " (263, 75),\n",
       " (264, 3),\n",
       " (265, 300),\n",
       " (266, 301),\n",
       " (267, 159),\n",
       " (268, 159),\n",
       " (269, 303),\n",
       " (270, 306),\n",
       " (271, 301),\n",
       " (272, 301),\n",
       " (273, 159),\n",
       " (274, 159),\n",
       " (275, 159),\n",
       " (276, 309),\n",
       " (277, 309),\n",
       " (278, 193),\n",
       " (279, 311),\n",
       " (280, 268),\n",
       " (281, 139),\n",
       " (282, 311),\n",
       " (283, 193),\n",
       " (284, 314),\n",
       " (285, 193),\n",
       " (286, 310),\n",
       " (287, 310),\n",
       " (288, 193),\n",
       " (289, 312),\n",
       " (290, 316),\n",
       " (291, 193),\n",
       " (292, 311),\n",
       " (293, 193),\n",
       " (294, 193),\n",
       " (295, 317),\n",
       " (296, 319),\n",
       " (297, 320),\n",
       " (298, 110)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_arm(self, t, unknown_article_ids, verbosity):\n",
    "    \"\"\"\n",
    "    Choose an arm to pull = query to matched to infowavepage t that it has not been matched yet.\n",
    "    :param t: page_id for queries to matched to.\n",
    "    :param unknown_item_ids: Indexes of query ids that page t has not rated yet.\n",
    "    :return: Received reward for matched query = 1/0 = page actually matched/unmatched query.\n",
    "    \"\"\"\n",
    "    var_A = tf.get_variable(\"varA\",[],dtype=tf.float64)\n",
    "    var_b = tf.get_variable(\"varb\",[],dtype=tf.float64)\n",
    "    \n",
    "    var_armfeatures = tf.get_variable(\"vararmf\",[],dtype=tf.float64)\n",
    "    arm_features = var_armfeatures[t]\n",
    "    \n",
    "    p_t = tf.Variable(tf.zeros((arm_features.shape[0], 1)), name=\"p_t\")\n",
    "    \n",
    "    page_ids = unknown_article_ids\n",
    "\n",
    "    \n",
    "    for a in page_ids:  # iterate over all arms, which are pages\n",
    "\n",
    "        x_ta = arm_features[a].reshape(arm_features[a].shape[0], 1)  # make a column vector\n",
    "        A_a_inv = np.linalg.inv(A[a])\n",
    "        theta_a = A_a_inv.dot(b[a])\n",
    "        \n",
    "        p_t[a] = theta_a.T.dot(x_ta) + self.alpha * np.sqrt(x_ta.T.dot(A_a_inv).dot(x_ta))\n",
    "        \n",
    "        \n",
    "    if self.allow_selecting_known_arms:\n",
    "        page_ids = range(self.num_articles)\n",
    "        p_t += 9999\n",
    "\n",
    "    for a in page_ids:  # iterate over all arms, which are pages\n",
    "        x_ta = arm_features[a].reshape(arm_features[a].shape[0], 1)  # make a column vector\n",
    "        \n",
    "        #A_a_inv = np.linalg.inv(A[a])\n",
    "        #theta_a = A_a_inv.dot(b[a])\n",
    "        \n",
    "        # solve the equation  theta_a = inv(A_a)*b_a\n",
    "        \n",
    "        theta_a = tf.squeeze(tf.linalg.solve(\n",
    "              tf.eye(context_dim) + a_new, tf.expand_dims(b_new, axis=-1)),axis=-1)\n",
    "        \n",
    "        # p_t_a <- theta_a'*x_t_a +  alpha*sqrt(x_t_a'*inv(A_a)*x_t_a)\n",
    "        \n",
    "        # inv(A_a)*x_t_a\n",
    "        g_t_a = tf.squeeze(tf.linalg.solve(tf.eye(context_dim)+a_new, tf.expand_dims(x_ta, axis=-1)), axis=-1)\n",
    "        \n",
    "        p_t[a] = tf.add(tf.tensordot(theta_a, x_ta)  + tf.tesnordot(alpha, tf.sqrt(tf.tensordot(x_ta, g_t_a))))\n",
    "\n",
    "    max_p_t=tf.argmax(p_t, axis=0).eval()\n",
    "     \n",
    "    if max_p_t <= 0:\n",
    "        print(\"Page {} has max p_t={}, p_t={}\".format(t, max_p_t, p_t))\n",
    "\n",
    "#     # I want to randomly break ties, np.argmax return the first occurence of maximum.\n",
    "#     # So I will get all occurences of the max and randomly select between them\n",
    "#     max_idxs = np.argwhere(p_t == max_p_t).flatten()\n",
    "#     a_t = np.random.choice(max_idxs)  # idx of article to recommend to query t\n",
    "\n",
    "    # observed reward = 1/0\n",
    "    r_t = self.recommend(query_id=t, page_id=a_t, fixed_rewards=self.fixed_rewards, prob_reward_p=self.prob_reward_p)\n",
    "\n",
    "    if verbosity >= 2:\n",
    "        print(\"Query {} choosing item {} with p_t={} reward {}\".format(t, a_t, p_t[a_t], r_t))\n",
    "\n",
    "    x_t_at = arm_features[a_t].reshape(arm_features[a_t].shape[0], 1)  # make a column vector\n",
    "    \n",
    "    \n",
    "    A[a_t] = A[a_t] + x_t_at.dot(x_t_at.T)\n",
    "    b[a_t] = b[a_t] + r_t * x_t_at.flatten()  # turn it back into an array because b[a_t] is an array\n",
    "\n",
    "    return r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.6273495 1.5908341 1.9122056 1.6450934 1.5816354 1.921754  1.4039447\n",
      " 1.8419342 1.7399813 1.7603672 2.057818  1.9557897 1.5122609 2.0516946\n",
      " 2.6383598 1.9520094 2.9556124 1.5188614 2.1218843 2.4499352 2.0489266\n",
      " 1.9914584 2.0133147 1.1502281 1.2770871 1.9000312 2.1164932 1.6031288\n",
      " 2.104098  2.862285  1.5444435 1.4385434 1.8306081 2.6178684 1.8674445\n",
      " 1.0612665 1.7758377 1.9116054 2.2810955 2.6134279 2.0456433 1.9411949\n",
      " 2.4280052 1.5860144 1.7309104 2.0248597 1.9476199 2.3774056 1.6243871\n",
      " 1.3179729 2.6794572 3.360909  2.2464557 3.5075924 1.61854   1.9108175\n",
      " 2.1492465 2.3186169 1.5784448 1.1996174 0.9756304 2.103008  1.9761904\n",
      " 1.1782299 1.7392672 2.8680365 2.119985  1.9168903 2.7379205 1.673472\n",
      " 1.9684135 1.8815335 2.416632  2.2824042 2.042732  2.2342448 1.7052974\n",
      " 1.4237059 1.5139753 1.9792188 2.6535387 2.4919696 2.8348465 1.5368046\n",
      " 1.7228323 2.191136  2.6167812 1.8678763 1.9779855 2.392957  1.7558525\n",
      " 1.5377384 2.3173935 2.737442  2.1648    2.0837088 1.4276077 2.1713724\n",
      " 2.007934  1.9198351 2.2241027 1.9972774 2.1584349 1.2643336 2.3133624\n",
      " 2.0689635 1.6618356 1.7774539 3.174484  3.5097308 1.4644197 2.6981428\n",
      " 2.7966905 2.853506  1.9727199 2.5041697 2.208614  2.2109404 2.215904\n",
      " 1.6986606 1.7892263 2.5168755 1.8911792 2.3094728 2.4086368 1.3411418\n",
      " 2.0082126 2.231818  1.6158417 1.666835  1.83697   1.1546901 1.9886558\n",
      " 2.5453956 1.210838  1.6511543 2.0979657 2.2401412 2.3692133 1.842735\n",
      " 2.6726074 2.5123549 1.9500825 2.404753  1.3534871 2.2106013 2.51149\n",
      " 2.5851064 2.4593997 2.5906203 2.307004  2.1129503 1.7500443 1.908388\n",
      " 2.4896839 1.9529198 2.713882  1.7070111 1.332228  1.4056005 3.0978534\n",
      " 1.5922505 1.3860734 1.9715179 2.2354755 3.2236652 1.9277638 2.1994808\n",
      " 1.5436944 1.6929207 1.6379406 1.0874856 1.0625367 2.2227635 1.6475122\n",
      " 1.7602841 1.2832252 1.3957876 2.166906  3.1250532 1.6180428 2.2481525\n",
      " 2.7006505 1.7150521 2.0278203 1.3900651 2.163486  1.5199792 3.4800627\n",
      " 2.96942   3.703615  2.550102  1.5360731 2.0060499 1.348018  1.8701173\n",
      " 2.407214  1.8618432 2.0286934 1.6025352 3.2455308 3.315389  2.3514843\n",
      " 2.6105883 1.8172148 1.6297268 1.9143128 3.550821  1.9002246 1.9091432\n",
      " 1.4597692 1.5029649 2.4983735 2.4963458 1.8127961 1.8660395 2.249881\n",
      " 1.6124012 1.6466155 1.968605  2.0610347 2.0537376 2.7615771 1.653001\n",
      " 2.3455591 1.7049919 2.2329729 1.3496281 2.039012  2.3503714 1.6126924\n",
      " 2.3589892 1.2939011 2.3273718 1.9598373 1.9407864 1.5150001 2.1762888\n",
      " 2.3941026 2.128507  1.9282633 1.460772  2.6835837 1.0891345 1.9472975\n",
      " 2.4056196 1.7972721 1.3534477 2.195702  1.5759408 1.9103514 1.960513\n",
      " 2.563535  1.7924783 1.5014908 2.0081084 0.8178167 2.1486762 1.4393078\n",
      " 2.4718986 2.5465586 2.952976  3.3233368 2.2044005 2.162011  1.8078195\n",
      " 2.9903955 2.0405028 2.1624079 3.1795466 1.657256  1.4480764 2.2119231\n",
      " 1.5626678 3.827762  1.5418361 1.8503872 2.213394  1.4634405 1.8263808\n",
      " 1.960539  2.1626048 1.1560435 2.163191  2.4649732 1.9240375 1.7509178\n",
      " 1.2406563 2.9900167 2.425258  2.1834319 2.2870178 1.9609694 1.396378\n",
      " 1.467395  2.4039772 1.5736439 1.9363645 2.0721998 2.214182  1.953309\n",
      " 2.900987  1.9561849 2.5863786 1.303016  1.7702227 2.9363573 3.1171324\n",
      " 1.8110633 2.475328  2.5842476 2.2943785 1.5056794 2.000488  2.2327576\n",
      " 1.9507797 1.1814824 1.3021252 1.3509939 1.8434384 2.2047985], shape=(321,), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "274\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'scatter_update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f536f0afcc7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m#     print(sess.run(A_a_t_new))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m#     print(A_a_t_new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_a_t_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;31m#     tf.compat.v1.scatter_nd_update()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m#     A[a_t].assign(A_a_t_new).eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'scatter_update'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "#tf.executing_eagerly()\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "num_articles=321\n",
    "num_arm_features=305\n",
    "\n",
    "alpha=0.1\n",
    "\n",
    "\n",
    "query_features=pickle.load(open('data/X_train_bow_features.pkl','rb'))\n",
    "page_features=pickle.load(open('data/X_all_page_pca_features.pkl','rb'))\n",
    "ratings = pickle.load(open('data/Y_train_labels.pkl','rb'))\n",
    "\n",
    "ident = tf.eye(num_arm_features)\n",
    "A = tf.Variable(tf.ones([num_articles, 1, 1], name='A') * ident)\n",
    "b = tf.Variable(tf.zeros([num_articles, num_arm_features], name='b'))\n",
    "\n",
    "# product = tf.matmul(ident3d[0,:], ident3d[0,:])\n",
    "\n",
    "# #initialize the variable\n",
    "#init_op = tf.initialize_all_variables()\n",
    "\n",
    "def initialize_arm_features(queryf,pagef):\n",
    "    X_query = tf.constant(queryf, dtype=tf.float32, name=\"X_query\")\n",
    "    X_page = tf.constant(pagef, dtype=tf.float32, name=\"X_page\")\n",
    "    return X_query, X_page\n",
    "\n",
    "def get_arm_features(i,j):\n",
    "    return tf.concat([X_query[i],X_page[j]],0)\n",
    "\n",
    "def recommend(query_id, page_id, ratings, fixed_rewards=True, prob_reward_p=0.9, ):\n",
    "    \"\"\"\n",
    "    Returns reward and updates rating maatrix self.R.\n",
    "    :param fixed_rewards: Whether to always return 1/0 rewards for already rated items.\n",
    "    :param prob_reward_p: Probability of returning the correct reward for already rated item.\n",
    "    :return: Reward = either 0 or 1.\n",
    "    \"\"\"\n",
    "    MIN_PROBABILITY = 0 # Minimal probability to like an item - adds stochasticity\n",
    "    \n",
    "    print(query_id)\n",
    "    print(page_id)\n",
    "    \n",
    "    if ratings[query_id, page_id] == 1:\n",
    "        if fixed_rewards:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.random.binomial(n=1, p=prob_reward_p)  # Bernoulli coin toss\n",
    "    else:\n",
    "\n",
    "        # the goal is to update a missing \"\"\n",
    "        current_page_features = page_features[page_id,:] #get the article features\n",
    "        current_query_features = query_features[query_id,:]  #get the article features\n",
    "\n",
    "        # find out for a page, what query is rated as relevant (which for new query should be none)\n",
    "        query_ratings = ratings[:,page_id]  #get all ratings by article id, it is a column\n",
    "        query_pos_rat_idxs = np.argwhere(query_ratings == 1).flatten() # get all other positive ratings of the same article\n",
    "        num_known_ratings = len(query_pos_rat_idxs)  # length of all other positive ratings\n",
    "\n",
    "        match_likabilities=[]\n",
    "\n",
    "        for query_idx in query_pos_rat_idxs:\n",
    "            match_likabilities.append(cosine_similarity(current_query_features.reshape(-1,1), query_features[query_idx].reshape(-1,1)))\n",
    "\n",
    "        result_match_likability = np.average(match_likabilities)\n",
    "\n",
    "        if math.isnan(result_match_likability):\n",
    "            result_match_likability=0\n",
    "\n",
    "        binomial_reward_probability = result_match_likability\n",
    "        #print (binomial_reward_probability)\n",
    "        if binomial_reward_probability <= 0:\n",
    "            #print(\"User={}, item={}, genre likability={}\".format(user_id, item_id, result_genre_likability))\n",
    "            binomial_reward_probability = MIN_PROBABILITY # this could be replaced by small probability\n",
    "\n",
    "        approx_rating = np.random.binomial(n=1, p=binomial_reward_probability)  # Bernoulli coin toss\n",
    "\n",
    "        if approx_rating == 1:\n",
    "            ratings[query_id, page_id] = 1\n",
    "        else:\n",
    "            ratings[query_id, page_id] = 0\n",
    "\n",
    "        #return approx_rating\n",
    "        return approx_rating\n",
    "    \n",
    "\n",
    "#run the graph\n",
    "\n",
    "t0 = time.time()\n",
    "#with tf.compat.v1.Session() as sess:\n",
    "X_query, X_page = initialize_arm_features(query_features, page_features)\n",
    "\n",
    "#p_t = tf.Variable(tf.zeros([321,]), dtype=tf.float32, name=\"p_t\")    \n",
    "#tf.global_variables_initializer().run()\n",
    "tf.compat.v1.global_variables_initializer()\n",
    "#print the random values that we sample\n",
    "\n",
    "for q_id in tf.range(600):\n",
    "    axt = []\n",
    "    for a in tf.range(321):\n",
    "        x_ta = get_arm_features(q_id,a)\n",
    "        A_new = A[a,:]\n",
    "        b_new = b[a,:]\n",
    "        theta_a = tf.squeeze(tf.linalg.solve(tf.eye(num_arm_features) + A_new, tf.expand_dims(b_new, axis=-1)),axis=-1)\n",
    "        g_t_a = tf.squeeze(tf.linalg.solve(tf.eye(num_arm_features)+A_new, tf.expand_dims(x_ta, axis=-1)), axis=-1)\n",
    "        #n_p = tf.add(tf.tensordot(theta_a, x_ta, (0,0)),tf.tensordot(alpha, tf.sqrt(tf.tensordot(x_ta, g_t_a, (0,0))),(0,0)))\n",
    "\n",
    "        temp=tf.math.add(tf.tensordot(theta_a, x_ta,(0,0)),tf.sqrt(tf.tensordot(x_ta, g_t_a, (0,0))))\n",
    "        axt.append(temp)\n",
    "#         print(type(n_p))\n",
    "#         print(sess.run(n_p))\n",
    "       #(n_p).eval()\n",
    "    p_t = tf.stack(axt)\n",
    "    #print(sess.run(p_t))\n",
    "\n",
    "    print(p_t)\n",
    "    max_p_t=tf.argmax(p_t, axis=0).numpy()\n",
    "    #print(max_p_t)\n",
    "\n",
    "    # need to add tile breaking\n",
    "    a_t = max_p_t\n",
    "\n",
    "\n",
    "    r_t = recommend(query_id=q_id, page_id=a_t, ratings=ratings)\n",
    "\n",
    "\n",
    "\n",
    "    x_t_at = get_arm_features(0,a_t) \n",
    "    A_a_t = A[a_t,:]\n",
    "    A_a_t_new = tf.add(A_a_t, tf.tensordot(x_t_at, x_t_at,(0,0)))\n",
    "    b_a_t_new = tf.add(b[a_t],r_t*x_t_at)\n",
    "#     print(sess.run(A_a_t_new))\n",
    "#     print(A_a_t_new)\n",
    "    tf.compat.v1.scatter_update(A,[a_t],A_a_t_new)\n",
    "#     tf.compat.v1.scatter_nd_update()\n",
    "#     A[a_t].assign(A_a_t_new).eval()\n",
    "    tf.compat.v1.scatter_update(b,[a_t],b_a_t_new)\n",
    "    #b[a_t] = b[a_t] + r_t * x_t_at.flatten()  # turn it back into an array because b[a_t] is an array\n",
    "        \n",
    "t1 = time.time()\n",
    "\n",
    "# assign approach timing is 649 s\n",
    "# append approach timing is 24 s\n",
    "\n",
    "\n",
    "print(\"total timing is {}\", str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(600)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_query.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Tensordot:0\", shape=(2, 2), dtype=float32)\t tf.einsum('i,j', a, b)\t\t- ((the last 0 axes of a), (the first 0 axes of b))\n",
      "Tensor(\"Tensordot_1:0\", shape=(2, 2), dtype=float32)\t tf.einsum('i,j', a, b)\t\t- ((() axis of a), (() axis of b))\n",
      "Tensor(\"Tensordot_2:0\", shape=(2, 2), dtype=float32)\t tf.einsum('i,j->ji', a, b)\t- ((the last 0 axes of b), (the first 0 axes of a))\n",
      "Tensor(\"Tensordot_3:0\", shape=(), dtype=float32)\t\t tf.einsum('i,i', a, b)\t\t- ((the last 1 axes of a), (the first 1 axes of b))\n",
      "Tensor(\"Tensordot_4:0\", shape=(), dtype=float32)\t\t tf.einsum('i,i', a, b)\t\t- ((0th axis of a), (0th axis of b))\n",
      "Tensor(\"Tensordot_5:0\", shape=(), dtype=float32)\t\t tf.einsum('i,i', a, b)\t\t- ((0th axis of a), (0th axis of b))\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2.])\n",
    "b = tf.constant([2,3.])\n",
    "print(f\"{tf.tensordot(a, b, 0)}\\t tf.einsum('i,j', a, b)\\t\\t- ((the last 0 axes of a), (the first 0 axes of b))\")\n",
    "print(f\"{tf.tensordot(a, b, ((),()))}\\t tf.einsum('i,j', a, b)\\t\\t- ((() axis of a), (() axis of b))\")\n",
    "print(f\"{tf.tensordot(b, a, 0)}\\t tf.einsum('i,j->ji', a, b)\\t- ((the last 0 axes of b), (the first 0 axes of a))\")\n",
    "print(f\"{tf.tensordot(a, b, 1)}\\t\\t tf.einsum('i,i', a, b)\\t\\t- ((the last 1 axes of a), (the first 1 axes of b))\")\n",
    "print(f\"{tf.tensordot(a, b, ((0,), (0,)))}\\t\\t tf.einsum('i,i', a, b)\\t\\t- ((0th axis of a), (0th axis of b))\")\n",
    "print(f\"{tf.tensordot(a, b, (0,0))}\\t\\t tf.einsum('i,i', a, b)\\t\\t- ((0th axis of a), (0th axis of b))\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(tf.constant([[1,1],[2,3]]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    change_v = v[0,0].assign(4)\n",
    "    print(sess.run(change_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = tf.constant([1,2.])\n",
    "    prod = tf.tensordot(a, a, 0)\n",
    "    print(sess.run(prod))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = tf.eye(num_arm_features)\n",
    "ident2 = tf.ones([num_arm_features,num_arm_features])\n",
    "A = tf.Variable(tf.ones([num_articles, 1, 1], name='A') * ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ScatterNdUpdate:0' shape=(321, 30, 30) dtype=float32_ref>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.scatter_nd_update(A,[0],ident2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ones_1:0' shape=(30, 30) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ident2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
